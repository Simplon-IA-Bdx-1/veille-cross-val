{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross-validation : avantages et inconvénients\n",
    "\n",
    "            - Vincent\n",
    "            - Yohan\n",
    "            - Pierre\n",
    "            - Nicolas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La cross-validation\n",
    "\n",
    "### Concepts\n",
    "\n",
    "- Séparation du jeu de données en vue d'entraîner et d'évaluer un modèle\n",
    "    - Différents types\n",
    "- Optimiser les hyperparamètres d'un modèle\n",
    "    - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cas d'application\n",
    "\n",
    "#### Train_Test_Split\n",
    "\n",
    "![train_test](img/train_test.png)\n",
    "\n",
    "L'estimation de la perfomance de notre modele peut s'en retrouvé biaisée car elle dépent des données qui vont se retrouver dans l'ensemble de validation ( par exemple un ensemble de validation qui comporterait uniquement des observations d'une meme classe dans un problème de classification) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### K-Fold\n",
    "\n",
    "- Peut servir de baseline\n",
    "- Plutôt adapté aux problèmes de regression\n",
    "- Augmente le biais quand le dataset est important => utilisation du train/val split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![k_folds](img/k_folds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Leave One Out\n",
    "Cas \"extrême \" de *K-Fold*: on on prend un nombre de folds égal au nombre d'observations du dataset , on verifie donc la perfomance du modele sur une seule observation à chaque fois\n",
    "\n",
    "- Forte augmentation du temps de calcul pour un gros dataset\n",
    "- Formation de jeux d'entrainement trés similaire entre eux ,  on aura quasiment le meme modéle sur chaque fold\n",
    "- Très peu utilisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Stratified KFold\n",
    "\n",
    "- Dans le cas d'un probleme de classification on s'assure de créer des k folds de sorte qu'elles contiennent à peu prés les memes proprotions d'exemple de chaque classe pour éviter de biaiser les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![strat](img/strat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "#### Avantages\n",
    "\n",
    "- permet de ne pas \"gaspiller\" des données (cas de petits datasets par exemple)\n",
    "- donne des informations suplémentaires par rapport au split test/val:\n",
    "    - estimation de la performance\n",
    "    - mesure la précision de l'information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Inconvénients\n",
    "\n",
    "- coûteux en temps de calcul\n",
    "- peu adapté aux très gros jeux de données (ex en Deep learning)\n",
    "- faire attention à la répartition des classes => StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Pour aller plus loin\n",
    "\n",
    "- Shuffle\n",
    "- GroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sources\n",
    "\n",
    "- [Documentation Sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "- [Vidéo didactique en fr.](https://www.youtube.com/watch?v=VoyMOVfCSfc&t=1136s)\n",
    "- [Livre](https://fr.calameo.com/read/000003587247e52d9457e)\n",
    "- [OpenClassroom](https://openclassrooms.com/fr/courses/4297211-evaluez-et-ameliorez-les-performances-dun-modele-de-machine-learning/4308241-mettez-en-place-un-cadre-de-validation-croisee)\n",
    "- [Recap Sklearn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)\n",
    "- Machine Learning Mastery with Python Chapitre 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple sur le Dataset Iris\n",
    "\n",
    "- Probleme de classification , prédire de quelle famille est une iris en fonction de 4 features ( longueur du pétale etc...)\n",
    "- 3 familles différentes distribuées de maniere égale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_train = iris.data\n",
    "y_train = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# K-fold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(5, random_state=0)\n",
    "\n",
    "cross_val_score(KNeighborsClassifier(), X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Leave one out\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "cross_val_score(KNeighborsClassifier(), X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle split\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(4, test_size=0.2)\n",
    "cross_val_score(KNeighborsClassifier(), X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stratified K-Folds\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(4)\n",
    "cross_val_score(KNeighborsClassifier(), X_train, y_train, cv=cv)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
