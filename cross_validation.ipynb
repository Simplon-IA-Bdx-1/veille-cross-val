{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation : avantages et inconvénients\n",
    "\n",
    "____\n",
    "\n",
    "Liens : \n",
    "- [Cours OpenClassrooms](https://openclassrooms.com/fr/courses/4297211-evaluez-et-ameliorez-les-performances-dun-modele-de-machine-learning/4308241-mettez-en-place-un-cadre-de-validation-croisee)\n",
    "- [Validation Croisée Yohan](https://fr.calameo.com/read/000003587247e52d9457e)\n",
    "- [Vidéo Pierrot Machine Learnia](https://www.youtube.com/watch?v=VoyMOVfCSfc&t=1136s)\n",
    "- [Dataset Iris sklearn](https://scikit-learn.org/stable/datasets/index.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ce qu'on faisait avant\n",
    "\n",
    "Split du dataset en un ensemble d'entrainement et un ensemble pour estimer la performance de notre modèle\n",
    "![train_test](img/train_test.png)\n",
    "\n",
    "L'estimation de la perfomance de notre modele peut s'en retrouvé biaisée car elle dépent des données qui vont se retrouver dans l'ensemble de validation ( par exemple un ensemble de validation qui comporterait uniquement des observations d'une meme classe dans un problème de classification) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La cross validation\n",
    "\n",
    "- La cross validation permet d'utiliser l'intégralité de notre jeu de donnée pour l'entrainement et la validation\n",
    "\n",
    "- Fonctionnement : split du jeu de donnée en k parties ( folds )  à peu prés égales , tour à tour chaque partie est utilisée comme jeu de test , le reste sert à entrainer le modéle\n",
    "- En général cette technique n'est pas utilisée en Deep Learning : \n",
    "    * Gros volume de données , il est peu problable d'avoir que des observations d'une classe dans un ensemble de validation\n",
    "    * Si on fait par exemple 5 splits , on doit entrainer 5 modeles , ce qui peut prendre beaucoup de temps dans le cadre de l'entrainement d'un modele de deep learning\n",
    "\n",
    "![k_folds](img/k_folds.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification\n",
    "\n",
    "- Dans le cas d'un probleme de classification on s'assure de créer des k folds de sorte qu'elles contiennent à peu prés les memes proprotions d'exemple de chaque classe pour éviter de biaiser les résultats\n",
    "\n",
    "![strat](img/strat.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Iris\n",
    "\n",
    "- Probleme de classification , prédire de quelle famille est une iris en fonction de 4 features ( longueur du pétale etc...)\n",
    "- 3 familles différentes distribuées de maniere égale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train = iris.data\n",
    "y_train = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold\n",
    "\n",
    "- Bon pour les problemes de régression\n",
    "- Mauvais quand les classes sont déséquilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.83333333, 0.93333333, 0.8       ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(5,random_state=0)\n",
    "# random_state = seed ?\n",
    "cross_val_score(KNeighborsClassifier(), X_train,y_train,cv=cv)\n",
    "# score = accuracy ? possibilité de spécifier quelle metric on veut "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One Out\n",
    "Cas \"extréme \" on on prend un nombre de folds égal au nombre d'observations du dataset , on verifie donc la perfomance du modele sur une seule observation à chaque fois\n",
    "\n",
    "- Forte augmentation du temps de calcul pour un gros dataset\n",
    "- Formation de jeux d'entrainement trés similaire entre eux ,  on aura quasiment le meme modéle sur chaque fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "cross_val_score(KNeighborsClassifier(), X_train,y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suffle Split\n",
    "\n",
    "- split train/v comme on le faisait avant , mais on remélange et on refait un split n fois en précisant quel pourcentage des données est utilisé pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93333333, 0.96666667, 0.96666667, 0.96666667])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = ShuffleSplit(4, test_size=0.2)\n",
    "cross_val_score(KNeighborsClassifier(), X_train,y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified KFold\n",
    "\n",
    "\n",
    "- commence par un tri des classes ( ex 1 ou 0 ) \n",
    "- en fonction du nombre de splits voulus , découpe de chaque classe en n split ( ex si on veut 4 splits , découpe de la classe 0 en 4 , découpe de la classe 1 en 4 )\n",
    "- on regroupe ensuite 2 par 2 chaque split.\n",
    "- On se retrouve ensuite avec 4 splits qui ont a peu prés la meme proprotion d'observation de la classe 1 et de la classe 0 \n",
    "\n",
    "Pas trés clair à l'écrit , mais bien expliqué dans la vidéo vers 15:00 =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(4)\n",
    "cross_val_score(KNeighborsClassifier(), X_train,y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  est ce qu'on parle du GroupKFold ( vidéo )  pas sur de savoir l'expliquer =) ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
